{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5946e2-2833-4279-9f90-18dcf3ad6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from warnings import warn\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc527dc-9e97-4cbb-80b7-af57a3787f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping(genre):\n",
    "    pages = [1,51,101,151,201,251,301,351,401,451,501]\n",
    "    URL1 = f'https://www.imdb.com/search/title/?title_type=feature&num_votes=10000,&genres={genre}&languages=en&sort=user_rating,desc&start='\n",
    "    URL2 = '&explore=genres&ref_=adv_nxt'\n",
    "    headers = {'Accept-Language': 'en-US,en;q=0.8'} # If this is not specified, the default language is Mandarin\n",
    "    \n",
    "    #initialize empty lists to store the variables scraped\n",
    "    genre_titles = []\n",
    "    genre_imdb_ids = []\n",
    "    genre_genres = []\n",
    "    genre_imgdata = []\n",
    "    genre_plot = []\n",
    "    \n",
    "    for page in pages:\n",
    "      \n",
    "       #get request for adventure\n",
    "       response = get(URL1\n",
    "                      + str(page)\n",
    "                      + URL2, headers=headers)\n",
    "      \n",
    "       sleep(randint(8,15))\n",
    "       \n",
    "       #throw warning for status codes that are not 200\n",
    "       if response.status_code != 200:\n",
    "           warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "    \n",
    "       #parse the content of current iteration of request\n",
    "       page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "          \n",
    "       movie_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "      \n",
    "       #extract the 50 movies for that page\n",
    "       for container in movie_containers:\n",
    "    \n",
    "            #title\n",
    "            title = container.h3.a.text\n",
    "            genre_titles.append(title)\n",
    "    \n",
    "            #imdb_id\n",
    "            imdb_id = container.find('a')['href'].strip().split('/')[-2]\n",
    "            genre_imdb_ids.append(imdb_id)\n",
    "    \n",
    "            #images\n",
    "            img = f'http://img.omdbapi.com/?i={imdb_id}&h=600&apikey=7c8ba5e4'\n",
    "            genre_imgdata.append(img)\n",
    "                \n",
    "            #genre\n",
    "            genre_name = container.p.find('span', class_ = 'genre').text.replace(\"\\n\", \"\").rstrip().split(',') # remove the whitespace character, strip, and split to create an array of genres\n",
    "            genre_genres.append(genre_name)\n",
    "            \n",
    "            #plot\n",
    "            plot_url = f'https://www.omdbapi.com/?i={imdb_id}&apikey=7c8ba5e4&plot=full'\n",
    "            response = requests.get(plot_url)\n",
    "            response.raise_for_status()  # raises exception when not a 2xx response\n",
    "            if response.status_code != 204:\n",
    "                response = response.json()\n",
    "            genre_plot.append(response['Plot'])\n",
    "            \n",
    "    df = pd.DataFrame({'movie': genre_titles,\n",
    "                          'imdb_id': genre_imdb_ids,\n",
    "                          'genre': genre_genres,\n",
    "                       'plot':genre_plot,\n",
    "                        'image_url':genre_imgdata}\n",
    "                              )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e80763-2b95-4e90-a900-37d86df6b92f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action_df = scrapping(\"action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503f9f6f-933a-4b62-b622-73e102872682",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adventure_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrapping\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madventure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [2], line 20\u001b[0m, in \u001b[0;36mscrapping\u001b[0;34m(genre)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n\u001b[1;32m     14\u001b[0m   \n\u001b[1;32m     15\u001b[0m    \u001b[38;5;66;03m#get request for adventure\u001b[39;00m\n\u001b[1;32m     16\u001b[0m    response \u001b[38;5;241m=\u001b[39m get(URL1\n\u001b[1;32m     17\u001b[0m                   \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(page)\n\u001b[1;32m     18\u001b[0m                   \u001b[38;5;241m+\u001b[39m URL2, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m---> 20\u001b[0m    \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m    \u001b[38;5;66;03m#throw warning for status codes that are not 200\u001b[39;00m\n\u001b[1;32m     23\u001b[0m    \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adventure_df = scrapping(\"adventure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa12b0-c6cf-4a8a-849f-33ae6ecb46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_df = scrapping(\"animation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa502d2b-4f52-451e-b2a0-196f4c027c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "biography_df = scrapping(\"biography\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98755d5-ee22-4eb5-a069-45304adfd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_df = scrapping(\"comedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c1f32-0f37-454e-ba25-d3a52a77cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df = scrapping(\"crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2b97f-50cb-4f81-a24e-7a0dad18f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentary_df = scrapping(\"documentary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f29493-ce92-4f69-900e-d66f5d929a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_df.to_csv('action_df.csv')\n",
    "adventure_df.to_csv('adventure_df.csv')\n",
    "animation_df.to_csv('animation_df.csv')\n",
    "biography_df.to_csv('biography_df.csv')\n",
    "comedy_df.to_csv('comedy_df.csv')\n",
    "crime_df.to_csv('crime_df.csv')\n",
    "documentary_df.to_csv('documentary_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc7ad56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = [\"Action\", \"Adventure\", \"Animation\", \"Biography\", \"Comedy\", \"Crime\", \"Documentary\",\"Drama\", \"Family\", \"Fantasy\", \"Film-Noir\", \"History\", \"Horror\", \"Music\", \"Musical\",\"Mystery\", \"Romance\", \"Sci-Fi\", \"Sport\", \"Thriller\", \"War\", \"Western\"]\n",
    "dataframes = []\n",
    "for i in genre_list:\n",
    "    df = scrapping(i)\n",
    "    dataframes.append(df)\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "merged_df.to_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e137dc2-a087-4ff4-be12-55be5378ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePoster(imdb_id, img_url):\n",
    "    '''\n",
    "    Function that fetches and save the poster image from provided url\n",
    "    and saves it with the provided id (corresponding with IMDb).\n",
    "    Won't replace (or even fetch) if file already exists.\n",
    "    \n",
    "    INPUT:  id from imdb, url where to find image\n",
    "    OUTPUT: boolean flag if saved or not.\n",
    "    '''\n",
    "    import os.path\n",
    "    \n",
    "    # Get file extension\n",
    "    ext = img_url.split('.')[-1]\n",
    "    \n",
    "    # Check to see if I already have it\n",
    "    if os.path.isfile(f'posters/{imdb_id}.{ext}'):\n",
    "        return False\n",
    "    \n",
    "    # Get image data, and save it as imdb_id\n",
    "    response = requests.get(img_url)\n",
    "    img = Image.open(BytesIO(response.content))    \n",
    "    img.save(f'posters/{imdb_id}.{ext}')\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49c47ba-7976-469f-b64c-4c811032ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory\n",
    "\n",
    "def download_photos(genre, df):\n",
    "    for index, row in df.iterrows():\n",
    "        img_data = requests.get(row['image_url']).content\n",
    "        imdb_id = row['imdb_id']\n",
    "        with open(create_dir(f\"{genre}\") + \"/\" + f'{imdb_id}.jpg', 'wb') as handler:\n",
    "            handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48e75927-5146-4ecf-a6d0-b25806b0d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_photos(\"animation\", animation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "793ec9c2-0857-48db-aa0b-10bc7facfbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_photos(\"biography\", biography_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a49a3b27-33d7-4b81-9a09-d98009d9e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_photos(\"comedy\", comedy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51f70b3b-aff6-4aee-8053-aae14f9f42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_photos(\"crime\", crime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec26f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_photos(\"all photo\", merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
