{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a299f4-6d90-4703-be31-0b64cbd761f8",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4ff3d-cf2b-4b80-9d5b-5e476d995206",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers \n",
    "# ==4.28.0\n",
    "!pip install scikit-multilearn\n",
    "!pip install accelerate -U\n",
    "!pip install tensorflow\n",
    "%env SM_FRAMEWORK=tensorflow.keras\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f09950-3508-47bc-8c13-6ed96784e9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting filelock (from torch)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/00/45/ec3407adf6f6b5bf867a4462b2b0af27597a26bd3cd6e2534cb6ab029938/filelock-3.12.2-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/jessica/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in /home/jessica/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch)\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: setuptools in /home/jessica/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (63.2.0)\n",
      "Requirement already satisfied: wheel in /home/jessica/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.0)\n",
      "Collecting cmake (from triton==2.0.0->torch)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/2e/51/3a4672a819b4532a378bfefad8f886cfe71057556e0d4eefb64523fd370a/cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lit (from triton==2.0.0->torch)\n",
      "  Using cached lit-16.0.6-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jessica/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Downloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.27.2 filelock-3.12.2 lit-16.0.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56148197-4294-4edb-9e31-53021e636f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 22:12:42.503923: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-18 22:12:44.138226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jessica/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "import string\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from time import sleep\n",
    "from string import punctuation\n",
    "from sklearn import metrics\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, TFBertModel\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict, Dataset\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b6d6d-285c-41d9-a411-15be01adb463",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd102db-5417-40c8-8bd2-02bb38f362e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_csv('long_sypnosis.csv').drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2d6a532-a098-4e68-82da-97e3c7aa9d5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4624/4624 [00:02<00:00, 1812.31it/s]\n"
     ]
    }
   ],
   "source": [
    "corrupted_list = []\n",
    "\n",
    "for img in tqdm(range(long_df.shape[0])):\n",
    "    try:\n",
    "        images_path = f\"/home/jessica/code/chooj202/movie_genre_prediction/notebooks/merged/{long_df['imdb_id'][img]}.jpg\"\n",
    "        image = Image.open(images_path)\n",
    "    except:\n",
    "        corrupted_list.append(long_df['imdb_id'][img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97ce74a3-ea80-4bf8-b883-293603091536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrupted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3015d50d-c533-4dee-b638-0fa58d71c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = long_df.loc[~long_df['imdb_id'].isin(corrupted_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73d18b73-0404-491e-9c67-a29e4f31f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = long_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8a89f-6852-460b-b0a4-2e13b9cdd59d",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "images -> resize and scale\n",
    "text -> word_ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8d449f5-6178-4a10-9d85-2c7346aed5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df[\"genre\"] = (\n",
    "    long_df[\"genre\"]\n",
    "    .apply(eval)\n",
    "    .apply(lambda x: [genre.strip() for genre in x])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5afa22ba-e299-4141-b840-60fef3eb12f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_url</th>\n",
       "      <th>sypnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>tt0259534</td>\n",
       "      <td>[Animation, Action, Adventure]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0259534&amp;h=600&amp;apik...</td>\n",
       "      <td>An anime adaptation of the Hindu epic the Rama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>[Action, Crime, Drama]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0468569&amp;h=600&amp;apik...</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>tt0167260</td>\n",
       "      <td>[Action, Adventure, Drama]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0167260&amp;h=600&amp;apik...</td>\n",
       "      <td>Gandalf and Aragorn lead the World of Men agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spider-Man: Across the Spider-Verse</td>\n",
       "      <td>tt9362722</td>\n",
       "      <td>[Animation, Action, Adventure]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt9362722&amp;h=600&amp;apik...</td>\n",
       "      <td>Miles Morales catapults across the Multiverse,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Message</td>\n",
       "      <td>tt0075143</td>\n",
       "      <td>[Action, Adventure, Biography]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0075143&amp;h=600&amp;apik...</td>\n",
       "      <td>The story of prophet \"Muhammad\" and the delive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           movie    imdb_id  \\\n",
       "0            Ramayana: The Legend of Prince Rama  tt0259534   \n",
       "1                                The Dark Knight  tt0468569   \n",
       "2  The Lord of the Rings: The Return of the King  tt0167260   \n",
       "3            Spider-Man: Across the Spider-Verse  tt9362722   \n",
       "4                                    The Message  tt0075143   \n",
       "\n",
       "                            genre  \\\n",
       "0  [Animation, Action, Adventure]   \n",
       "1          [Action, Crime, Drama]   \n",
       "2      [Action, Adventure, Drama]   \n",
       "3  [Animation, Action, Adventure]   \n",
       "4  [Action, Adventure, Biography]   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  http://img.omdbapi.com/?i=tt0259534&h=600&apik...   \n",
       "1  http://img.omdbapi.com/?i=tt0468569&h=600&apik...   \n",
       "2  http://img.omdbapi.com/?i=tt0167260&h=600&apik...   \n",
       "3  http://img.omdbapi.com/?i=tt9362722&h=600&apik...   \n",
       "4  http://img.omdbapi.com/?i=tt0075143&h=600&apik...   \n",
       "\n",
       "                                            sypnosis  \n",
       "0  An anime adaptation of the Hindu epic the Rama...  \n",
       "1  When the menace known as the Joker wreaks havo...  \n",
       "2  Gandalf and Aragorn lead the World of Men agai...  \n",
       "3  Miles Morales catapults across the Multiverse,...  \n",
       "4  The story of prophet \"Muhammad\" and the delive...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6870d5b-b1d9-4fb7-9351-2433bfb46095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentence):\n",
    "\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "\n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c53b407-c2f8-4a06-b122-a67e30f0a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df['sypnosis'] = long_df['sypnosis'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d240f7f-79c0-4915-b981-5ceab7c347cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_url</th>\n",
       "      <th>sypnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>tt0259534</td>\n",
       "      <td>[Animation, Action, Adventure]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0259534&amp;h=600&amp;apik...</td>\n",
       "      <td>an anime adaptation of the hindu epic the rama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>[Action, Crime, Drama]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0468569&amp;h=600&amp;apik...</td>\n",
       "      <td>when the menace known as the joker wreaks havo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>tt0167260</td>\n",
       "      <td>[Action, Adventure, Drama]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0167260&amp;h=600&amp;apik...</td>\n",
       "      <td>gandalf and aragorn lead the world of men agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spider-Man: Across the Spider-Verse</td>\n",
       "      <td>tt9362722</td>\n",
       "      <td>[Animation, Action, Adventure]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt9362722&amp;h=600&amp;apik...</td>\n",
       "      <td>miles morales catapults across the multiverse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Message</td>\n",
       "      <td>tt0075143</td>\n",
       "      <td>[Action, Adventure, Biography]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0075143&amp;h=600&amp;apik...</td>\n",
       "      <td>the story of prophet muhammad and the delivery...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           movie    imdb_id  \\\n",
       "0            Ramayana: The Legend of Prince Rama  tt0259534   \n",
       "1                                The Dark Knight  tt0468569   \n",
       "2  The Lord of the Rings: The Return of the King  tt0167260   \n",
       "3            Spider-Man: Across the Spider-Verse  tt9362722   \n",
       "4                                    The Message  tt0075143   \n",
       "\n",
       "                            genre  \\\n",
       "0  [Animation, Action, Adventure]   \n",
       "1          [Action, Crime, Drama]   \n",
       "2      [Action, Adventure, Drama]   \n",
       "3  [Animation, Action, Adventure]   \n",
       "4  [Action, Adventure, Biography]   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  http://img.omdbapi.com/?i=tt0259534&h=600&apik...   \n",
       "1  http://img.omdbapi.com/?i=tt0468569&h=600&apik...   \n",
       "2  http://img.omdbapi.com/?i=tt0167260&h=600&apik...   \n",
       "3  http://img.omdbapi.com/?i=tt9362722&h=600&apik...   \n",
       "4  http://img.omdbapi.com/?i=tt0075143&h=600&apik...   \n",
       "\n",
       "                                            sypnosis  \n",
       "0  an anime adaptation of the hindu epic the rama...  \n",
       "1  when the menace known as the joker wreaks havo...  \n",
       "2  gandalf and aragorn lead the world of men agai...  \n",
       "3  miles morales catapults across the multiverse ...  \n",
       "4  the story of prophet muhammad and the delivery...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3a32759-e107-4215-9d9e-b2f11896e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "def balanced_split(df, mlb, test_size=0.5):\n",
    "    ind = np.expand_dims(np.arange(len(df)), axis=1)\n",
    "    mlb.fit_transform(df[\"genre\"])\n",
    "    labels = mlb.transform(df[\"genre\"])\n",
    "    ind_train, _, ind_test, _ = iterative_train_test_split(\n",
    "        ind, labels, test_size\n",
    "    )\n",
    "    return df.iloc[ind_train[:, 0]], df.iloc[ind_test[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b6caf7d-1289-4217-9815-6598ad4cce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = balanced_split(long_df, mlb, test_size=0.2)\n",
    "# df_val, df_test = balanced_split(df_tmp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6bfef0cd-152b-4c5a-9c0c-61fa9a72c252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3136, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24ac8d9c-580c-460f-985e-f26368204467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop = True)\n",
    "df_test = df_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc56ff2f-509b-4860-9f85-69174e1cd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('stack_train.csv')\n",
    "df_test.to_csv('stack_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc4b1ffa-0793-480e-ab89-c25982bedcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b22de5d-4f9c-48c0-83a6-ba89108e85db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3136/3136 [1:07:23<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = []\n",
    "\n",
    "for img in tqdm(range(df_train.shape[0])):\n",
    "    images_path = f\"/home/jessica/code/chooj202/movie_genre_prediction/notebooks/merged/{df_train['imdb_id'][img]}.jpg\"\n",
    "    image = Image.open(images_path)\n",
    "    image = image.resize((224, 224))\n",
    "    train_imgs.append(np.array(image))\n",
    "    time.sleep(1)\n",
    "    np.save('train_img', train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5b1f8d4-9341-4658-91dd-953314412e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.array(train_imgs)\n",
    "np.save('train_imgs', train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc19be01-43f2-4657-b89f-1e360cb348b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 807/807 [13:37<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "test_imgs = []\n",
    "\n",
    "for img in tqdm(range(df_test.shape[0])):\n",
    "    images_path = f\"/home/jessica/code/chooj202/movie_genre_prediction/notebooks/merged/{df_test['imdb_id'][img]}.jpg\"\n",
    "    image = Image.open(images_path)\n",
    "    image = image.resize((224, 224))\n",
    "    test_imgs.append(np.array(image))\n",
    "    time.sleep(1)\n",
    "\n",
    "test_imgs = np.array(test_imgs)\n",
    "np.save('test_imgs', test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bef166f8-ab01-4195-a311-8f6f03759ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_train['genre'])\n",
    "\n",
    "#transform target variable\n",
    "y_train = multilabel_binarizer.transform(df_train['genre'])\n",
    "genre_names = multilabel_binarizer.classes_\n",
    "\n",
    "# Adding\n",
    "for i in range(len(genre_names)):\n",
    "    df_train[f\"{genre_names[i]}\"] = y_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "728e6599-3415-46dc-b239-600bd7c2bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_test['genre'])\n",
    "\n",
    "#transform target variable\n",
    "y_test = multilabel_binarizer.transform(df_test['genre'])\n",
    "genre_names = multilabel_binarizer.classes_\n",
    "\n",
    "# Adding\n",
    "for i in range(len(genre_names)):\n",
    "    df_test[f\"{genre_names[i]}\"] = y_test[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30a6d303-d551-445b-a56e-a830b7ac8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train_stack', y_train)\n",
    "np.save('y_test_stack', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "185095c3-0cad-4a06-8ec2-c845a4f01cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_url</th>\n",
       "      <th>sypnosis</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>tt0259534</td>\n",
       "      <td>[Animation, Action, Adventure]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0259534&amp;h=600&amp;apik...</td>\n",
       "      <td>an anime adaptation of the hindu epic the rama...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>[Action, Crime, Drama]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0468569&amp;h=600&amp;apik...</td>\n",
       "      <td>when the menace known as the joker wreaks havo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spider-Man: Across the Spider-Verse</td>\n",
       "      <td>tt9362722</td>\n",
       "      <td>[Animation, Action, Adventure]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt9362722&amp;h=600&amp;apik...</td>\n",
       "      <td>miles morales catapults across the multiverse ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inception</td>\n",
       "      <td>tt1375666</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt1375666&amp;h=600&amp;apik...</td>\n",
       "      <td>a thief who steals corporate secrets through t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>tt0167261</td>\n",
       "      <td>[Action, Adventure, Drama]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0167261&amp;h=600&amp;apik...</td>\n",
       "      <td>while frodo and sam edge closer to mordor with...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   movie    imdb_id  \\\n",
       "0    Ramayana: The Legend of Prince Rama  tt0259534   \n",
       "1                        The Dark Knight  tt0468569   \n",
       "2    Spider-Man: Across the Spider-Verse  tt9362722   \n",
       "3                              Inception  tt1375666   \n",
       "4  The Lord of the Rings: The Two Towers  tt0167261   \n",
       "\n",
       "                            genre  \\\n",
       "0  [Animation, Action, Adventure]   \n",
       "1          [Action, Crime, Drama]   \n",
       "2  [Animation, Action, Adventure]   \n",
       "3     [Action, Adventure, Sci-Fi]   \n",
       "4      [Action, Adventure, Drama]   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  http://img.omdbapi.com/?i=tt0259534&h=600&apik...   \n",
       "1  http://img.omdbapi.com/?i=tt0468569&h=600&apik...   \n",
       "2  http://img.omdbapi.com/?i=tt9362722&h=600&apik...   \n",
       "3  http://img.omdbapi.com/?i=tt1375666&h=600&apik...   \n",
       "4  http://img.omdbapi.com/?i=tt0167261&h=600&apik...   \n",
       "\n",
       "                                            sypnosis  Action  Adventure  \\\n",
       "0  an anime adaptation of the hindu epic the rama...       1          1   \n",
       "1  when the menace known as the joker wreaks havo...       1          0   \n",
       "2  miles morales catapults across the multiverse ...       1          1   \n",
       "3  a thief who steals corporate secrets through t...       1          1   \n",
       "4  while frodo and sam edge closer to mordor with...       1          1   \n",
       "\n",
       "   Animation  Biography  Comedy  ...  Horror  Music  Musical  Mystery  \\\n",
       "0          1          0       0  ...       0      0        0        0   \n",
       "1          0          0       0  ...       0      0        0        0   \n",
       "2          1          0       0  ...       0      0        0        0   \n",
       "3          0          0       0  ...       0      0        0        0   \n",
       "4          0          0       0  ...       0      0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Sport  Thriller  War  Western  \n",
       "0        0       0      0         0    0        0  \n",
       "1        0       0      0         0    0        0  \n",
       "2        0       0      0         0    0        0  \n",
       "3        0       1      0         0    0        0  \n",
       "4        0       0      0         0    0        0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6bee42f0-ff91-4425-9a81-be42a00bbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_text = df_train['sypnosis'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d04f97fc-0883-4fff-b59b-8fbea5470979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f7647cff-7ab8-4c19-9019-8ea03651fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "test_text = df_test['sypnosis'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c3dc947a-07fb-46a1-9cdd-32a3b1c54371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bdf3b-0667-47cc-b75e-42e63ec9bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(str(train_text), truncation=True, padding=True, max_length=128, return_tensors=\"np\")\n",
    "test_encodings = tokenizer(str(test_text), truncation=True, padding=True, max_length=128, return_tensors=\"np\")\n",
    "\n",
    "train_encodings = dict(train_encodings)\n",
    "test_encodings = dict(valid_encodings)\n",
    "\n",
    "# model.fit(train_encodings, tf.convert_to_tensor(y_train), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ee2bc594-9dd9-44e0-85a2-d47d4b94168a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101,  1031,  1005,  2019,  8750,  6789,  1997,  1996,  7560,\n",
       "          8680,  1996, 14115, 16811,  2073,  2935,  8223,  4337,  2015,\n",
       "          1996, 10433,  2332, 10958, 27313,  1996, 10392,  2466,  1997,\n",
       "         14115,  1037,  2402,  3159,  2040,  2038,  2042, 21319,  2000,\n",
       "          1996,  3224,  2011,  2010, 26959,  2002,  2003,  2104,  1996,\n",
       "          3860,  1997,  2010,  2564,  4133,  2050,  1998,  2010,  2567,\n",
       "          2474,  5705, 13890,  2043,  1037,  3928,  5698,  2332, 10958,\n",
       "          6212, 19935, 14194,  3215,  4133,  2050, 14115, 13416,  2046,\n",
       "          4000,  1998, 14038,  2021,  2002, 12237,  2844,  1998,  9590,\n",
       "          2002,  2442,  2954,  6750,  7942,  2491,  2010, 14038,  1998,\n",
       "          2954,  2127,  2010,  2564,  2003,  2489,  1517, 14115,  1996,\n",
       "          8987,  3159,  1997,  1037,  7677, 16425,  3148, 14115,  2003,\n",
       "         14146,  2005,  7426,  2086,  2000,  1996,  3224,  2010,  2564,\n",
       "          4133,  2050,  1998,  2567,  2474,  5705, 13890,  2050,  3693,\n",
       "          2032,   102]]),\n",
       " 'token_type_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3da0f7f2-4033-4336-9e1b-31d47518d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_stack\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(valid_encodings, fp)\n",
    "\n",
    "# >>> with open(\"test\", \"rb\") as fp:   # Unpickling\n",
    "# ...   b = pickle.load(fp)\n",
    "# ... \n",
    "# >>> b\n",
    "# [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "41ccff23-9454-4180-9320-2d894663b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_stack\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(train_encodings, fp)\n",
    "\n",
    "# >>> with open(\"test\", \"rb\") as fp:   # Unpickling\n",
    "# ...   b = pickle.load(fp)\n",
    "# ... \n",
    "# >>> b\n",
    "# [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b2593c8b-ce7f-4996-a7e1-25b691b4c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test_text['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e088e5d-2b42-4526-9369-2d1b7dedbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_text['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e01d71f3-7775-48f9-979e-886f464db4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and split into train/test sets\n",
    "# REMEMBER TO DROP COLUMNS!!\n",
    "X_train_img = train_imgs\n",
    "X_train_text = train_encodings['input_ids']\n",
    "y_train = y_train\n",
    "X_test_img = test_imgs\n",
    "X_test_text = valid_encodings['input_ids']\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fe51d988-c147-4a1c-a662-64ee310ce1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "888dbffe-aaff-46fb-a157-25556d0b3178",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c223fcd2-1cd5-4e83-96c0-06d31828a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN-based image feature extractor\n",
    "def build_image_model():\n",
    " img_model = tf.keras.Sequential([\n",
    " tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    " tf.keras.layers.MaxPooling2D((2, 2)),\n",
    " tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D((2, 2)),\n",
    " tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D((2, 2)),\n",
    " tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D((2, 2)),\n",
    " tf.keras.layers.Flatten(),\n",
    " tf.keras.layers.Dense(512, activation='relu')\n",
    " ])\n",
    " return img_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3037b0-8881-4bae-87ea-5e45ffb8b67f",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "22068806-d30a-4a99-bb57-8634b4a727a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the BERT-based text feature extractor\n",
    "def build_text_model():\n",
    " bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    " inputs = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_word_ids')\n",
    " outputs = bert_model(inputs)[1]\n",
    " text_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    " return text_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e9b35-96f9-46ff-90d3-c47c7c0a42a7",
   "metadata": {},
   "source": [
    "## Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fcd45939-8327-4f03-89e1-c8b6399e3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the multimodal document classification model\n",
    "def build_multimodal_model(num_classes):\n",
    " img_model = build_image_model()\n",
    " text_model = build_text_model()\n",
    " img_input = tf.keras.layers.Input(shape=(224, 224, 3), name='img_input')\n",
    " text_input = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='text_input')\n",
    " img_features = img_model(img_input)\n",
    " text_features = text_model(text_input)\n",
    " concat_features = tf.keras.layers.concatenate([img_features, text_features])\n",
    " x = tf.keras.layers.Dense(512, activation='relu')(concat_features)\n",
    " x = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    " multimodal_model = tf.keras.Model(inputs=[img_input, text_input], outputs=x)\n",
    " return multimodal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "025cb8dd-dedf-469f-b808-40ebf19ce74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_input (InputLayer)      [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " text_input (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 512)                  9678528   ['img_input[0][0]']           \n",
      "                                                                                                  \n",
      " model_2 (Functional)        (None, 768)                  1094822   ['text_input[0][0]']          \n",
      "                                                          40                                      \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 1280)                 0         ['sequential_1[0][0]',        \n",
      " )                                                                   'model_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 512)                  655872    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 21)                   10773     ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 119827413 (457.11 MB)\n",
      "Trainable params: 119827413 (457.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the multimodal model\n",
    "num_classes = 21\n",
    "multimodal_model = build_multimodal_model(num_classes)\n",
    "multimodal_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a91dd087-d74c-4e01-9f7e-ea03cc2118c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 3136, 1\n  y sizes: 3136\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# compile the model and train on the train set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m multimodal_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmultimodal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_img\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_img\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1943\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1944\u001b[0m         label,\n\u001b[1;32m   1945\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1946\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1947\u001b[0m         ),\n\u001b[1;32m   1948\u001b[0m     )\n\u001b[1;32m   1949\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1950\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3136, 1\n  y sizes: 3136\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# compile the model and train on the train set\n",
    "multimodal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'f1', 'roc_auc'])\n",
    "\n",
    "multimodal_model.fit([tf.convert_to_tensor(X_train_img), tf.convert_to_tensor(X_train_text)], tf.convert_to_tensor(y_train), epochs=2, batch_size=32, validation_data=([tf.convert_to_tensor(X_test_img), tf.convert_to_tensor(X_test_text)], tf.convert_to_tensor(y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
