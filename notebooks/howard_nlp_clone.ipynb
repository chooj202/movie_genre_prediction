{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from warnings import warn\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras import layers, Sequential, callbacks, optimizers, utils, models, applications\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_NAMES = [\"action\", \"adventure\", \"animation\", \"biography\", \"comedy\", \"crime\", \"drama\", \"family\", \"fantasy\", \"film-noir\", \"history\", \"horror\", \"music\", \"musical\", \"mystery\", \"romance\", \"scifi\", \"sport\", \"thriller\", \"war\", \"western\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ls = [f'../raw_data/500_points/{genre_name}.csv' for genre_name in GENRE_NAMES]\n",
    "df = pd.concat(\n",
    "    map(pd.read_csv, path_ls), ignore_index=True)\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RN'] = df.sort_values(['imdb_id']).groupby(['imdb_id']).cumcount() + 1\n",
    "merged_df = df[df['RN'] == 1].drop(columns=['RN', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4237, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>plot</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>tt0259534</td>\n",
       "      <td>['Animation', ' Action', ' Adventure']</td>\n",
       "      <td>The fantastic story of Rama, a young prince wh...</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0259534&amp;h=600&amp;apik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Legend of Maula Jatt</td>\n",
       "      <td>tt4139928</td>\n",
       "      <td>['Action', ' Drama', ' Fantasy']</td>\n",
       "      <td>From times untold where legends are written in...</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt4139928&amp;h=600&amp;apik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>tt0103064</td>\n",
       "      <td>['Action', ' Sci-Fi']</td>\n",
       "      <td>Over 10 years have passed since the first mach...</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0103064&amp;h=600&amp;apik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>tt0172495</td>\n",
       "      <td>['Action', ' Adventure', ' Drama']</td>\n",
       "      <td>Maximus is a powerful Roman general, loved by ...</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt0172495&amp;h=600&amp;apik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>tt1345836</td>\n",
       "      <td>['Action', ' Drama', ' Thriller']</td>\n",
       "      <td>Despite his tarnished reputation after the eve...</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt1345836&amp;h=600&amp;apik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  movie    imdb_id  \\\n",
       "0   Ramayana: The Legend of Prince Rama  tt0259534   \n",
       "11             The Legend of Maula Jatt  tt4139928   \n",
       "12           Terminator 2: Judgment Day  tt0103064   \n",
       "14                            Gladiator  tt0172495   \n",
       "16                The Dark Knight Rises  tt1345836   \n",
       "\n",
       "                                     genre  \\\n",
       "0   ['Animation', ' Action', ' Adventure']   \n",
       "11        ['Action', ' Drama', ' Fantasy']   \n",
       "12                   ['Action', ' Sci-Fi']   \n",
       "14      ['Action', ' Adventure', ' Drama']   \n",
       "16       ['Action', ' Drama', ' Thriller']   \n",
       "\n",
       "                                                 plot  \\\n",
       "0   The fantastic story of Rama, a young prince wh...   \n",
       "11  From times untold where legends are written in...   \n",
       "12  Over 10 years have passed since the first mach...   \n",
       "14  Maximus is a powerful Roman general, loved by ...   \n",
       "16  Despite his tarnished reputation after the eve...   \n",
       "\n",
       "                                            image_url  \n",
       "0   http://img.omdbapi.com/?i=tt0259534&h=600&apik...  \n",
       "11  http://img.omdbapi.com/?i=tt4139928&h=600&apik...  \n",
       "12  http://img.omdbapi.com/?i=tt0103064&h=600&apik...  \n",
       "14  http://img.omdbapi.com/?i=tt0172495&h=600&apik...  \n",
       "16  http://img.omdbapi.com/?i=tt1345836&h=600&apik...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('../raw_data/long_sypnosis/long_sypnosis.csv')\n",
    "merged_df[\"plot\"] = merged_df[\"sypnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentence):\n",
    "    \n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    \n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize \n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "    \n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "    \n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "    \n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"clean_plot\"] = merged_df[\"plot\"].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m merged_df[\u001b[39m\"\u001b[39m\u001b[39mgenre\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     merged_df[\u001b[39m\"\u001b[39;49m\u001b[39mgenre\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m----> 3\u001b[0m     \u001b[39m.\u001b[39;49mapply(\u001b[39meval\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     \u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: [genre\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m genre \u001b[39min\u001b[39;00m x])\n\u001b[1;32m      5\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/movie_genre_prediction/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "merged_df[\"genre\"] = (\n",
    "    merged_df[\"genre\"]\n",
    "    .apply(eval)\n",
    "    .apply(lambda x: [genre.strip() for genre in x])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Drama        2824\n",
       "Comedy       1495\n",
       "Adventure    1045\n",
       "Action        994\n",
       "Crime         806\n",
       "Romance       647\n",
       "Biography     591\n",
       "Thriller      544\n",
       "Horror        511\n",
       "Mystery       504\n",
       "Animation     405\n",
       "Fantasy       387\n",
       "Sci-Fi        360\n",
       "Family        312\n",
       "History       298\n",
       "Music         261\n",
       "War           201\n",
       "Sport         187\n",
       "Musical       106\n",
       "Western       104\n",
       "Film-Noir      59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the genre we have\n",
    "merged_df[\"genre\"].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(merged_df[\"genre\"])\n",
    "\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(merged_df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4624, 21)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4624, 29)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_names = multilabel_binarizer.classes_\n",
    "\n",
    "# Adding \n",
    "for i in range(len(genre_names)):\n",
    "    merged_df[f\"{genre_names[i]}\"] = y[:,i]\n",
    "\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(merged_df['clean_plot'], y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the TfidfVectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=0.05, max_features=10000)\n",
    "\n",
    "# Training it on the texts\n",
    "X_train_vec = pd.DataFrame(tf_idf_vectorizer.fit_transform(X_train).toarray(),\n",
    "                 columns = tf_idf_vectorizer.get_feature_names_out())\n",
    "X_test_vec =  pd.DataFrame(tf_idf_vectorizer.transform(X_test).toarray(),\n",
    "                 columns = tf_idf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accompany</th>\n",
       "      <th>account</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>years</th>\n",
       "      <th>yell</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abandon  ability      able  aboard  abuse  accept  accident  accidentally  \\\n",
       "0  0.000000      0.0  0.000000     0.0    0.0     0.0       0.0      0.000000   \n",
       "1  0.000000      0.0  0.000000     0.0    0.0     0.0       0.0      0.000000   \n",
       "2  0.000000      0.0  0.000000     0.0    0.0     0.0       0.0      0.010517   \n",
       "3  0.012096      0.0  0.000000     0.0    0.0     0.0       0.0      0.000000   \n",
       "4  0.009029      0.0  0.042081     0.0    0.0     0.0       0.0      0.000000   \n",
       "\n",
       "   accompany   account  ...  writer  wrong  year  yearold     years  yell  \\\n",
       "0        0.0  0.000000  ...     0.0    0.0   0.0      0.0  0.038444   0.0   \n",
       "1        0.0  0.000000  ...     0.0    0.0   0.0      0.0  0.000000   0.0   \n",
       "2        0.0  0.013621  ...     0.0    0.0   0.0      0.0  0.038424   0.0   \n",
       "3        0.0  0.000000  ...     0.0    0.0   0.0      0.0  0.000000   0.0   \n",
       "4        0.0  0.000000  ...     0.0    0.0   0.0      0.0  0.017441   0.0   \n",
       "\n",
       "        yet  york     young   younger  \n",
       "0  0.000000   0.0  0.000000  0.266858  \n",
       "1  0.000000   0.0  0.000000  0.000000  \n",
       "2  0.009824   0.0  0.017009  0.000000  \n",
       "3  0.000000   0.0  0.034480  0.000000  \n",
       "4  0.000000   0.0  0.020589  0.000000  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accompany</th>\n",
       "      <th>account</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>years</th>\n",
       "      <th>yell</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034626</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032793</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abandon  ability      able    aboard     abuse    accept  accident  \\\n",
       "0  0.060737      0.0  0.000000  0.000000  0.082595  0.000000       0.0   \n",
       "1  0.000000      0.0  0.000000  0.000000  0.000000  0.061568       0.0   \n",
       "2  0.000000      0.0  0.000000  0.039505  0.000000  0.000000       0.0   \n",
       "3  0.000000      0.0  0.000000  0.000000  0.000000  0.070866       0.0   \n",
       "4  0.000000      0.0  0.109184  0.000000  0.000000  0.000000       0.0   \n",
       "\n",
       "   accidentally  accompany  account  ...  writer  wrong  year   yearold  \\\n",
       "0      0.000000        0.0      0.0  ...     0.0    0.0   0.0  0.000000   \n",
       "1      0.149790        0.0      0.0  ...     0.0    0.0   0.0  0.000000   \n",
       "2      0.182483        0.0      0.0  ...     0.0    0.0   0.0  0.000000   \n",
       "3      0.000000        0.0      0.0  ...     0.0    0.0   0.0  0.045905   \n",
       "4      0.000000        0.0      0.0  ...     0.0    0.0   0.0  0.000000   \n",
       "\n",
       "      years  yell  yet  york     young  younger  \n",
       "0  0.000000   0.0  0.0   0.0  0.034626      0.0  \n",
       "1  0.045606   0.0  0.0   0.0  0.000000      0.0  \n",
       "2  0.000000   0.0  0.0   0.0  0.032793      0.0  \n",
       "3  0.000000   0.0  0.0   0.0  0.000000      0.0  \n",
       "4  0.000000   0.0  0.0   0.0  0.026710      0.0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRest logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple OneVsRest logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "model_test_1 = OneVsRestClassifier(log)\n",
    "\n",
    "model_test_1.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_test_1.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06628242074927954"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Drama',)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer.inverse_transform(y_pred)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>movie</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_url</th>\n",
       "      <th>sypnosis</th>\n",
       "      <th>plot</th>\n",
       "      <th>clean_plot</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>1539</td>\n",
       "      <td>Puncture</td>\n",
       "      <td>tt1582248</td>\n",
       "      <td>[Biography, Drama]</td>\n",
       "      <td>http://img.omdbapi.com/?i=tt1582248&amp;h=600&amp;apik...</td>\n",
       "      <td>A David and Goliath law drama about a drug-add...</td>\n",
       "      <td>A David and Goliath law drama about a drug-add...</td>\n",
       "      <td>david goliath law drama drugaddicted lawyer ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     movie    imdb_id               genre  \\\n",
       "1539        1539  Puncture  tt1582248  [Biography, Drama]   \n",
       "\n",
       "                                              image_url  \\\n",
       "1539  http://img.omdbapi.com/?i=tt1582248&h=600&apik...   \n",
       "\n",
       "                                               sypnosis  \\\n",
       "1539  A David and Goliath law drama about a drug-add...   \n",
       "\n",
       "                                                   plot  \\\n",
       "1539  A David and Goliath law drama about a drug-add...   \n",
       "\n",
       "                                             clean_plot  Action  Adventure  \\\n",
       "1539  david goliath law drama drugaddicted lawyer ta...       0          0   \n",
       "\n",
       "      ...  Horror  Music  Musical  Mystery  Romance  Sci-Fi  Sport  Thriller  \\\n",
       "1539  ...       0      0        0        0        0       0      0         0   \n",
       "\n",
       "      War  Western  \n",
       "1539    0        0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df.clean_plot == X_test.iat[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(max_iter=1000, n_components=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(max_iter=1000, n_components=15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(max_iter=1000, n_components=15)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Instantiate the LDA \n",
    "n_components = 15\n",
    "lda_model = LatentDirichletAllocation(n_components=n_components, max_iter = 1000)\n",
    "\n",
    "# Fit the LDA on the vectorized documents\n",
    "lda_model.fit(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880753</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.008518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.877313</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.008763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.922893</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871125</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.902430</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.006969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>0.908023</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.006570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>0.908247</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>0.924147</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.005418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>0.761994</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>0.936716</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.004520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3236 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.880753  0.008518  0.008518  0.008518  0.008518  0.008518  0.008518   \n",
       "1     0.877313  0.008763  0.008763  0.008763  0.008763  0.008763  0.008763   \n",
       "2     0.922893  0.005508  0.005508  0.005508  0.005508  0.005508  0.005508   \n",
       "3     0.871125  0.009205  0.009205  0.009205  0.009205  0.009205  0.009205   \n",
       "4     0.902430  0.006969  0.006969  0.006969  0.006969  0.006969  0.006969   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3231  0.908023  0.006570  0.006570  0.006570  0.006570  0.006570  0.006570   \n",
       "3232  0.908247  0.006554  0.006554  0.006554  0.006554  0.006554  0.006554   \n",
       "3233  0.924147  0.005418  0.005418  0.005418  0.005418  0.005418  0.005418   \n",
       "3234  0.761994  0.017000  0.017000  0.017000  0.017000  0.017000  0.017000   \n",
       "3235  0.936716  0.004520  0.004520  0.004520  0.004520  0.004520  0.004520   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0     0.008518  0.008518  0.008518  0.008518  0.008518  0.008518  0.008518   \n",
       "1     0.008763  0.008763  0.008763  0.008763  0.008763  0.008763  0.008763   \n",
       "2     0.005508  0.005508  0.005508  0.005508  0.005508  0.005508  0.005508   \n",
       "3     0.009205  0.009205  0.009205  0.009205  0.009205  0.009205  0.009205   \n",
       "4     0.006969  0.006969  0.006969  0.006969  0.006969  0.006969  0.006969   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3231  0.006570  0.006570  0.006570  0.006570  0.006570  0.006570  0.006570   \n",
       "3232  0.006554  0.006554  0.006554  0.006554  0.006554  0.006554  0.006554   \n",
       "3233  0.005418  0.005418  0.005418  0.005418  0.005418  0.005418  0.005418   \n",
       "3234  0.017000  0.017000  0.017000  0.017000  0.017000  0.017000  0.017000   \n",
       "3235  0.004520  0.004520  0.004520  0.004520  0.004520  0.004520  0.004520   \n",
       "\n",
       "            14  \n",
       "0     0.008518  \n",
       "1     0.008763  \n",
       "2     0.005508  \n",
       "3     0.009205  \n",
       "4     0.006969  \n",
       "...        ...  \n",
       "3231  0.006570  \n",
       "3232  0.006554  \n",
       "3233  0.005418  \n",
       "3234  0.017000  \n",
       "3235  0.004520  \n",
       "\n",
       "[3236 rows x 15 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_topic_mixture = lda_model.transform(X_train_vec)\n",
    "X_train_topic_df = pd.DataFrame(X_train_topic_mixture)\n",
    "X_train_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.886877</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899865</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921653</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.005596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.919883</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.005723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864347</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.009689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>0.920492</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.005679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.881270</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.008481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>0.928230</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>0.819829</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.012869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>0.891758</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1388 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.886877  0.008080  0.008080  0.008080  0.008080  0.008080  0.008080   \n",
       "1     0.899865  0.007152  0.007152  0.007152  0.007152  0.007152  0.007152   \n",
       "2     0.921653  0.005596  0.005596  0.005596  0.005596  0.005596  0.005596   \n",
       "3     0.919883  0.005723  0.005723  0.005723  0.005723  0.005723  0.005723   \n",
       "4     0.864347  0.009689  0.009689  0.009689  0.009689  0.009689  0.009689   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1383  0.920492  0.005679  0.005679  0.005679  0.005679  0.005679  0.005679   \n",
       "1384  0.881270  0.008481  0.008481  0.008481  0.008481  0.008481  0.008481   \n",
       "1385  0.928230  0.005126  0.005126  0.005126  0.005126  0.005126  0.005126   \n",
       "1386  0.819829  0.012869  0.012869  0.012869  0.012869  0.012869  0.012869   \n",
       "1387  0.891758  0.007732  0.007732  0.007732  0.007732  0.007732  0.007732   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0     0.008080  0.008080  0.008080  0.008080  0.008080  0.008080  0.008080   \n",
       "1     0.007152  0.007152  0.007152  0.007152  0.007152  0.007152  0.007152   \n",
       "2     0.005596  0.005596  0.005596  0.005596  0.005596  0.005596  0.005596   \n",
       "3     0.005723  0.005723  0.005723  0.005723  0.005723  0.005723  0.005723   \n",
       "4     0.009689  0.009689  0.009689  0.009689  0.009689  0.009689  0.009689   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1383  0.005679  0.005679  0.005679  0.005679  0.005679  0.005679  0.005679   \n",
       "1384  0.008481  0.008481  0.008481  0.008481  0.008481  0.008481  0.008481   \n",
       "1385  0.005126  0.005126  0.005126  0.005126  0.005126  0.005126  0.005126   \n",
       "1386  0.012869  0.012869  0.012869  0.012869  0.012869  0.012869  0.012869   \n",
       "1387  0.007732  0.007732  0.007732  0.007732  0.007732  0.007732  0.007732   \n",
       "\n",
       "            14  \n",
       "0     0.008080  \n",
       "1     0.007152  \n",
       "2     0.005596  \n",
       "3     0.005723  \n",
       "4     0.009689  \n",
       "...        ...  \n",
       "1383  0.005679  \n",
       "1384  0.008481  \n",
       "1385  0.005126  \n",
       "1386  0.012869  \n",
       "1387  0.007732  \n",
       "\n",
       "[1388 rows x 15 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_topic_mixture = lda_model.transform(X_test_vec)\n",
    "X_test_topic_df = pd.DataFrame(X_test_topic_mixture)\n",
    "X_test_topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training OneVsRest using topic grouping as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_2 = OneVsRestClassifier(log)\n",
    "model_test_2.fit(X_train_topic_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06628242074927954"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2 = model_test_2.predict(X_test_topic_df)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer.inverse_transform(y_pred_2)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 'Fantasy', 'Horror'),\n",
       " ('Biography', 'Drama'),\n",
       " ('Comedy', 'Family'),\n",
       " ('Comedy', 'Romance', 'Sci-Fi'),\n",
       " ('Comedy', 'Drama', 'Music'),\n",
       " ('Action', 'Drama', 'War'),\n",
       " ('Drama', 'Thriller'),\n",
       " ('Animation', 'Comedy', 'Drama'),\n",
       " ('Action', 'Adventure', 'Comedy'),\n",
       " ('Crime', 'Drama', 'Thriller')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer.inverse_transform(y_test)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using both topic grouping as input + OneVsRest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_3 = OneVsRestClassifier(log)\n",
    "model_test_3.fit(X_train_topic_df, y_train)\n",
    "model_test_3.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025157232704402517"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_3 = model_test_2.predict(X_test_topic_df)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=SGDClassifier(random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=SGDClassifier(random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(random_state=42))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(random_state = 42)\n",
    "sgd_model = OneVsRestClassifier(sgd)\n",
    "sgd_model.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sgd1 = sgd_model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " (),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',),\n",
       " ('Drama',)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer.inverse_transform(y_pred_sgd1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019654088050314465"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_sgd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_genre_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
