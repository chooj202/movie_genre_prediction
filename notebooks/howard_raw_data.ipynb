{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from warnings import warn\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping(genre):\n",
    "    pages = [1,51,101,151,201]\n",
    "    URL1 = f'https://www.imdb.com/search/title/?title_type=feature&num_votes=10000,&genres={genre}&languages=en&sort=user_rating,desc&start='\n",
    "    URL2 = '&explore=genres&ref_=adv_nxt'\n",
    "    headers = {'Accept-Language': 'en-US,en;q=0.8'} # If this is not specified, the default language is Mandarin\n",
    "    #initialize empty lists to store the variables scraped\n",
    "    genre_titles = []\n",
    "    genre_imdb_ids = []\n",
    "    genre_genres = []\n",
    "    genre_imgdata = []\n",
    "    genre_plot = []\n",
    "    for page in pages:\n",
    "       #get request for adventure\n",
    "       response = get(URL1\n",
    "                      + str(page)\n",
    "                      + URL2, headers=headers)\n",
    "       sleep(randint(8,15))\n",
    "       #throw warning for status codes that are not 200\n",
    "       if response.status_code != 200:\n",
    "           warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "       #parse the content of current iteration of request\n",
    "       page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "       movie_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "       #extract the 50 movies for that page\n",
    "       for container in movie_containers:\n",
    "            #title\n",
    "            title = container.h3.a.text\n",
    "            genre_titles.append(title)\n",
    "            #imdb_id\n",
    "            imdb_id = container.find('a')['href'].strip().split('/')[-2]\n",
    "            genre_imdb_ids.append(imdb_id)\n",
    "            #images\n",
    "            img = f'http://img.omdbapi.com/?i={imdb_id}&h=600&apikey=7c8ba5e4'\n",
    "            genre_imgdata.append(img)\n",
    "            #genre\n",
    "            genre_name = container.p.find('span', class_ = 'genre').text.replace(\"\\n\", \"\").rstrip().split(',') # remove the whitespace character, strip, and split to create an array of genres\n",
    "            genre_genres.append(genre_name)\n",
    "            #plot\n",
    "            plot_url = f'https://www.omdbapi.com/?i={imdb_id}&apikey=7c8ba5e4&plot=full'\n",
    "            response = requests.get(plot_url)\n",
    "            response.raise_for_status()  # raises exception when not a 2xx response\n",
    "            if response.status_code != 204:\n",
    "                response = response.json()\n",
    "            genre_plot.append(response['Plot'])\n",
    "    df = pd.DataFrame({\n",
    "        'movie': genre_titles,\n",
    "        'imdb_id': genre_imdb_ids,\n",
    "        'genre': genre_genres,\n",
    "        'plot':genre_plot,\n",
    "        'image_url':genre_imgdata}\n",
    "                              )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return directory\n",
    "\n",
    "def download_photos(genre, df):\n",
    "    for index, row in df.iterrows():\n",
    "        img_data = requests.get(row['image_url']).content\n",
    "        imdb_id = row['imdb_id']\n",
    "        with open(create_dir(f\"../raw_data/posters/{genre}\") + \"/\" + f'{imdb_id}.jpg', 'wb') as handler:\n",
    "            handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting horror\n",
      "done scrapping horror\n",
      "done downloading photos of horror\n",
      "starting music\n",
      "done scrapping music\n",
      "done downloading photos of music\n",
      "starting musical\n",
      "done scrapping musical\n",
      "done downloading photos of musical\n"
     ]
    }
   ],
   "source": [
    "genres = [\"horror\", \"music\", \"musical\"]\n",
    "for genre in genres:\n",
    "    print(f\"starting {genre}\")\n",
    "    df = scrapping(genre)\n",
    "    print(f\"done scrapping {genre}\")\n",
    "    download_photos(genre, df)\n",
    "    print(f\"done downloading photos of {genre}\")\n",
    "    df.to_csv(f\"../raw_data/{genre}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_genre_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
